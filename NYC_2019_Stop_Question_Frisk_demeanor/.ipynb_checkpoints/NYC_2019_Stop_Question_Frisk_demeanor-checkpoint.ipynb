{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from wordcloud import WordCloud\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "\n",
    "custom_style = {'axes.titlesize':'15',\n",
    "                'axes.titlecolor':'white',\n",
    "                'xtick.color': 'black',\n",
    "                'ytick.color': 'black'}\n",
    "sns.set(style= 'darkgrid', rc=custom_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqf = pd.read_csv('2019_sqf_race_demenour.csv')\n",
    "sqf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for empty cells \n",
    "sqf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the whole row if either race or demeanor is empty (small % anyway)\n",
    "sqf.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the demeanor to string\n",
    "sqf['split'] = sqf['demeanor_of_person_stopped'].apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order alphabetically\n",
    "sqf.sort_values(by='demeanor_of_person_stopped',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting 2 obvious spelling mistakes (had unique symbol)\n",
    "sqf['demeanor_of_person_stopped'].loc[2790] = 'UNCOOPERATIVE'\n",
    "sqf['demeanor_of_person_stopped'].loc[5875] = 'UPSET, COOPERATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace instances of NON with NON-\n",
    "sqf['demeanor_of_person_stopped'] = sqf['demeanor_of_person_stopped'].apply(\n",
    "    lambda x: x.replace(\"NON \", \"NON-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqf['split'] = sqf['demeanor_of_person_stopped'].apply(lambda x : re.findall('[a-zA-Z\\-]+',x))\n",
    "sqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spellchecker object\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that does the spell check \n",
    "\n",
    "def spellcheck(split_array): \n",
    "    return_array = []\n",
    "    for word in split_array:\n",
    "        return_array.append(spell.correction(word).upper())\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell check the split array and return array of correct spelling \n",
    "sqf['spellcheck_demeanor'] = sqf['split'].apply(lambda x: spellcheck(x))\n",
    "sqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of words \n",
    "def word_count(total_words_array):\n",
    "    counts = dict()\n",
    "    \n",
    "    for word in total_words_array:\n",
    "        if word in counts: \n",
    "            counts[word] += 1\n",
    "        else: \n",
    "            counts[word] = 1\n",
    "    return counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = [x.upper() for x in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will accept a series and produce a dataframe of word counts for the series\n",
    "def race_word_count(spellcheck_demeanor_race):\n",
    "    ''' accept a series and produce a dataframe of word counts for the series '''\n",
    "    words_array = []\n",
    "    \n",
    "    for row in spellcheck_demeanor_race: \n",
    "        for r in row:\n",
    "            if r not in stop_words: \n",
    "                words_array.append(r)\n",
    "                \n",
    "    df_word_count = pd.DataFrame.from_dict(word_count(words_array),\n",
    "                                       orient='Index',columns=['Count'])\n",
    "\n",
    "    return df_word_count.sort_values('Count',ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for suspects by race \n",
    "black_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'BLACK']['spellcheck_demeanor'])\n",
    "white_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "black_hispanic_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'BLACK HISPANIC']['spellcheck_demeanor'])\n",
    "white_hispanic_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'WHITE HISPANIC']['spellcheck_demeanor'])\n",
    "asian_pacific_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'ASIAN / PACIFIC ISLANDER']['spellcheck_demeanor'])\n",
    "native_alaskan_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'AMERICAN INDIAN/ALASKAN N']['spellcheck_demeanor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the count columns; individual race datasetes \n",
    "white_word_count.rename(columns={'Count':'white_count'},inplace=True)\n",
    "black_word_count.rename(columns={'Count':'black_count'},inplace=True)\n",
    "white_hispanic_word_count.rename(columns={'Count':'white_hispanic_count'},inplace=True)\n",
    "black_hispanic_word_count.rename(columns={'Count':'black_hispanic_count'},inplace=True)\n",
    "asian_pacific_word_count.rename(columns={'Count':'asian_pacific_count'},inplace=True)\n",
    "native_alaskan_word_count.rename(columns={'Count':'native_alaskan_count'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete dataframe of all records\n",
    "df_total_count = pd.concat([white_word_count, black_word_count, white_hispanic_word_count,\n",
    "                           black_hispanic_word_count, asian_pacific_word_count, \n",
    "                           native_alaskan_word_count], axis=1)\n",
    "df_total_count.head(10)\n",
    "# df_total_count.to_csv('2019_word_cloud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree = pd.DataFrame(sqf.groupby(['suspect_race_description']).count()['stop_id'])\n",
    "df_tree.reset_index(inplace=True)\n",
    "df_tree.columns = ['suspect_race_description','stop_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (12,12))\n",
    "squarify.plot(sizes=df_tree['stop_count'],\n",
    "              label=df_tree['suspect_race_description'],\n",
    "             alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_words(spellcheck_demeanor_race):\n",
    "    '''function accepts a series and returns a string of words'''\n",
    "    string_words = \"\"\n",
    "\n",
    "    for row in series: \n",
    "        for r in row:\n",
    "            if r not in stop_words: \n",
    "                  string_words = string_words + \" \" + r\n",
    "    \n",
    "    return string_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def black_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return \"hsl(0, 1%, 30%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor']\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the top 50 words for each race and removing the ones that aren't an emotion\n",
    "white_word_count.head(55)\n",
    "\n",
    "# words that should be removed \"extremely\", \"apparently\", \"highly\", \"profusely\"\n",
    "white_string_words = string_words(sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "white_string_words = white_string_words.replace(\"EXTREMELY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"APPARENTLY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"HIGHLY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"PROFUSELY\", \" \")\n",
    "white_string_words\n",
    "wordcloud = WordCloud(width = 720, height = 1200, font_path='Arial',\n",
    "                      background_color=None, max_words = 25,\n",
    "                      mode='RGBA',\n",
    "                      prefer_horizontal=0.9,\n",
    "                      collocations=False, color_func= black_color_func).generate(white_string_words)\n",
    "wordcloud.to_file(\"white_cloud.png\")\n",
    "plt.figure(figsize = (15, 11), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.title('White Word Cloud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the top 50 words for each race and removing the ones that aren't an emotion\n",
    "black_word_count.head(55)\n",
    "\n",
    "# words that should be removed \"apparently\", \"highly\", \"stop\", \"person\"\n",
    "black_string_words = string_words(sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "black_string_words = black_string_words.replace(\"STOP\", \" \")\n",
    "black_string_words = black_string_words.replace(\"APPARENTLY\", \" \")\n",
    "black_string_words = black_string_words.replace(\"HIGHLY\", \" \")\n",
    "black_string_words = black_string_words.replace(\"PERSON\", \" \")\n",
    "black_string_words\n",
    "wordcloud = WordCloud(width =1500, height = 900, font_path='Arial',\n",
    "                      background_color=None, max_words = 25,\n",
    "                      mode='RGBA',\n",
    "                      prefer_horizontal=0.85,\n",
    "                      collocations=False, color_func= black_color_func).generate(black_string_words)\n",
    "wordcloud.to_file(\"black_cloud.png\")\n",
    "plt.figure(figsize = (15, 11), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.title('White Word Cloud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = string_words(series)\n",
    "\n",
    "wordcloud = WordCloud(width =800, height = 800, \n",
    "                      background_color='white', max_words = 50,\n",
    "                      collocations=False).generate(output)\n",
    "plt.figure(figsize = (10, 10), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_word_count.head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor']\n",
    "output = string_words(series)\n",
    "\n",
    "wordcloud = WordCloud(width =800, height = 800, \n",
    "                      background_color='white', max_words = 50,\n",
    "                      collocations=False).generate(output)\n",
    "plt.figure(figsize = (10, 10), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
