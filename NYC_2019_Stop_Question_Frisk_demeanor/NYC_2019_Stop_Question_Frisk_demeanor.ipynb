{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/livernteo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from wordcloud import WordCloud\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "\n",
    "custom_style = {'axes.titlesize':'15',\n",
    "                'axes.titlecolor':'white',\n",
    "                'xtick.color': 'black',\n",
    "                'ytick.color': 'black'}\n",
    "sns.set(style= 'darkgrid', rc=custom_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>suspect_race_description</th>\n",
       "      <th>demeanor_of_person_stopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>UNDERSTANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-2</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-3</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>CALM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-4</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>CONFUSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-6</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>COORPERATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stop_id suspect_race_description demeanor_of_person_stopped\n",
       "0  2019-1                    BLACK              UNDERSTANDING\n",
       "1  2019-2                    BLACK                     NORMAL\n",
       "2  2019-3                    WHITE                       CALM\n",
       "3  2019-4                    BLACK                   CONFUSED\n",
       "4  2019-6                    BLACK               COORPERATIVE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqf = pd.read_csv('2019_sqf_race_demenour.csv')\n",
    "sqf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>suspect_race_description</th>\n",
       "      <th>demeanor_of_person_stopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13272</td>\n",
       "      <td>13184</td>\n",
       "      <td>13218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12313</td>\n",
       "      <td>6</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2.02E+12</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>CALM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>960</td>\n",
       "      <td>7854</td>\n",
       "      <td>4037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stop_id suspect_race_description demeanor_of_person_stopped\n",
       "count      13272                    13184                      13218\n",
       "unique     12313                        6                       1887\n",
       "top     2.02E+12                    BLACK                       CALM\n",
       "freq         960                     7854                       4037"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for empty cells \n",
    "sqf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the whole row if either race or demeanor is empty (small % anyway)\n",
    "sqf.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the demeanor to string\n",
    "sqf['split'] = sqf['demeanor_of_person_stopped'].apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order alphabetically\n",
    "sqf.sort_values(by='demeanor_of_person_stopped',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting 2 obvious spelling mistakes (had unique symbol)\n",
    "sqf['demeanor_of_person_stopped'].loc[2790] = 'UNCOOPERATIVE'\n",
    "sqf['demeanor_of_person_stopped'].loc[5875] = 'UPSET, COOPERATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace instances of NON with NON-\n",
    "sqf['demeanor_of_person_stopped'] = sqf['demeanor_of_person_stopped'].apply(\n",
    "    lambda x: x.replace(\"NON \", \"NON-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>suspect_race_description</th>\n",
       "      <th>demeanor_of_person_stopped</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>2019-7520</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>\"AFRAID\"</td>\n",
       "      <td>[AFRAID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11572</th>\n",
       "      <td>2019-12676</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>\"CALM\"</td>\n",
       "      <td>[CALM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2019-2014</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>- ANGRY AND SLIGHTLY UNCOOPERATIVE -</td>\n",
       "      <td>[-, ANGRY, AND, SLIGHTLY, UNCOOPERATIVE, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>2019-3035</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>UNCOOPERATIVE</td>\n",
       "      <td>[UNCOOPERATIVE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>2019-6423</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>UPSET, COOPERATIVE</td>\n",
       "      <td>[UPSET, COOPERATIVE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>2019-8318</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>YELLING</td>\n",
       "      <td>[YELLING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8829</th>\n",
       "      <td>2019-9738</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>YELLING</td>\n",
       "      <td>[YELLING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>2019-1209</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>YELLING AND LAUGHING</td>\n",
       "      <td>[YELLING, AND, LAUGHING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>2019-1208</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>YELLING AND LAUGHING</td>\n",
       "      <td>[YELLING, AND, LAUGHING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2019-1207</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>YELLING, AND LAUGHING</td>\n",
       "      <td>[YELLING, AND, LAUGHING]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stop_id suspect_race_description  \\\n",
       "6864    2019-7520                    BLACK   \n",
       "11572  2019-12676           WHITE HISPANIC   \n",
       "1882    2019-2014           WHITE HISPANIC   \n",
       "2790    2019-3035                    BLACK   \n",
       "5875    2019-6423                    BLACK   \n",
       "...           ...                      ...   \n",
       "7575    2019-8318                    BLACK   \n",
       "8829    2019-9738                    BLACK   \n",
       "1161    2019-1209                    BLACK   \n",
       "1160    2019-1208                    BLACK   \n",
       "1159    2019-1207                    BLACK   \n",
       "\n",
       "                 demeanor_of_person_stopped  \\\n",
       "6864                               \"AFRAID\"   \n",
       "11572                                \"CALM\"   \n",
       "1882   - ANGRY AND SLIGHTLY UNCOOPERATIVE -   \n",
       "2790                          UNCOOPERATIVE   \n",
       "5875                     UPSET, COOPERATIVE   \n",
       "...                                     ...   \n",
       "7575                                YELLING   \n",
       "8829                                YELLING   \n",
       "1161                   YELLING AND LAUGHING   \n",
       "1160                   YELLING AND LAUGHING   \n",
       "1159                  YELLING, AND LAUGHING   \n",
       "\n",
       "                                             split  \n",
       "6864                                      [AFRAID]  \n",
       "11572                                       [CALM]  \n",
       "1882   [-, ANGRY, AND, SLIGHTLY, UNCOOPERATIVE, -]  \n",
       "2790                               [UNCOOPERATIVE]  \n",
       "5875                          [UPSET, COOPERATIVE]  \n",
       "...                                            ...  \n",
       "7575                                     [YELLING]  \n",
       "8829                                     [YELLING]  \n",
       "1161                      [YELLING, AND, LAUGHING]  \n",
       "1160                      [YELLING, AND, LAUGHING]  \n",
       "1159                      [YELLING, AND, LAUGHING]  \n",
       "\n",
       "[13131 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqf['split'] = sqf['demeanor_of_person_stopped'].apply(lambda x : re.findall('[a-zA-Z\\-]+',x))\n",
    "sqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spellchecker object\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that does the spell check \n",
    "\n",
    "def spellcheck(split_array): \n",
    "    return_array = []\n",
    "    for word in split_array:\n",
    "        return_array.append(spell.correction(word).upper())\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell check the split array and return array of correct spelling \n",
    "sqf['spellcheck_demeanor'] = sqf['split'].apply(lambda x: spellcheck(x))\n",
    "sqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of words \n",
    "def word_count(total_words_array):\n",
    "    counts = dict()\n",
    "    \n",
    "    for word in total_words_array:\n",
    "        if word in counts: \n",
    "            counts[word] += 1\n",
    "        else: \n",
    "            counts[word] = 1\n",
    "    return counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = [x.upper() for x in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will accept a series and produce a dataframe of word counts for the series\n",
    "def race_word_count(spellcheck_demeanor_race):\n",
    "    ''' accept a series and produce a dataframe of word counts for the series '''\n",
    "    words_array = []\n",
    "    \n",
    "    for row in spellcheck_demeanor_race: \n",
    "        for r in row:\n",
    "            if r not in stop_words: \n",
    "                words_array.append(r)\n",
    "                \n",
    "    df_word_count = pd.DataFrame.from_dict(word_count(words_array),\n",
    "                                       orient='Index',columns=['Count'])\n",
    "\n",
    "    return df_word_count.sort_values('Count',ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for suspects by race \n",
    "black_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'BLACK']['spellcheck_demeanor'])\n",
    "white_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "black_hispanic_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'BLACK HISPANIC']['spellcheck_demeanor'])\n",
    "white_hispanic_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'WHITE HISPANIC']['spellcheck_demeanor'])\n",
    "asian_pacific_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'ASIAN / PACIFIC ISLANDER']['spellcheck_demeanor'])\n",
    "native_alaskan_word_count = race_word_count(\n",
    "    sqf[sqf['suspect_race_description'] == 'AMERICAN INDIAN/ALASKAN N']['spellcheck_demeanor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the count columns; individual race datasetes \n",
    "white_word_count.rename(columns={'Count':'white_count'},inplace=True)\n",
    "black_word_count.rename(columns={'Count':'black_count'},inplace=True)\n",
    "white_hispanic_word_count.rename(columns={'Count':'white_hispanic_count'},inplace=True)\n",
    "black_hispanic_word_count.rename(columns={'Count':'black_hispanic_count'},inplace=True)\n",
    "asian_pacific_word_count.rename(columns={'Count':'asian_pacific_count'},inplace=True)\n",
    "native_alaskan_word_count.rename(columns={'Count':'native_alaskan_count'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete dataframe of all records\n",
    "df_total_count = pd.concat([white_word_count, black_word_count, white_hispanic_word_count,\n",
    "                           black_hispanic_word_count, asian_pacific_word_count, \n",
    "                           native_alaskan_word_count], axis=1)\n",
    "df_total_count.head(10)\n",
    "# df_total_count.to_csv('2019_word_cloud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree = pd.DataFrame(sqf.groupby(['suspect_race_description']).count()['stop_id'])\n",
    "df_tree.reset_index(inplace=True)\n",
    "df_tree.columns = ['suspect_race_description','stop_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (12,12))\n",
    "squarify.plot(sizes=df_tree['stop_count'],\n",
    "              label=df_tree['suspect_race_description'],\n",
    "             alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_words(spellcheck_demeanor_race):\n",
    "    '''function accepts a series and returns a string of words'''\n",
    "    string_words = \"\"\n",
    "\n",
    "    for row in series: \n",
    "        for r in row:\n",
    "            if r not in stop_words: \n",
    "                  string_words = string_words + \" \" + r\n",
    "    \n",
    "    return string_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def black_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return \"hsl(0, 1%, 30%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor']\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the top 50 words for each race and removing the ones that aren't an emotion\n",
    "white_word_count.head(55)\n",
    "\n",
    "# words that should be removed \"extremely\", \"apparently\", \"highly\", \"profusely\"\n",
    "white_string_words = string_words(sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "white_string_words = white_string_words.replace(\"EXTREMELY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"APPARENTLY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"HIGHLY\", \" \")\n",
    "white_string_words = white_string_words.replace(\"PROFUSELY\", \" \")\n",
    "white_string_words\n",
    "wordcloud = WordCloud(width = 720, height = 1200, font_path='Arial',\n",
    "                      background_color=None, max_words = 25,\n",
    "                      mode='RGBA',\n",
    "                      prefer_horizontal=0.9,\n",
    "                      collocations=False, color_func= black_color_func).generate(white_string_words)\n",
    "wordcloud.to_file(\"white_cloud.png\")\n",
    "plt.figure(figsize = (15, 11), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.title('White Word Cloud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the top 50 words for each race and removing the ones that aren't an emotion\n",
    "black_word_count.head(55)\n",
    "\n",
    "# words that should be removed \"apparently\", \"highly\", \"stop\", \"person\"\n",
    "black_string_words = string_words(sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor'])\n",
    "black_string_words = black_string_words.replace(\"STOP\", \" \")\n",
    "black_string_words = black_string_words.replace(\"APPARENTLY\", \" \")\n",
    "black_string_words = black_string_words.replace(\"HIGHLY\", \" \")\n",
    "black_string_words = black_string_words.replace(\"PERSON\", \" \")\n",
    "black_string_words\n",
    "wordcloud = WordCloud(width =1500, height = 900, font_path='Arial',\n",
    "                      background_color=None, max_words = 25,\n",
    "                      mode='RGBA',\n",
    "                      prefer_horizontal=0.85,\n",
    "                      collocations=False, color_func= black_color_func).generate(black_string_words)\n",
    "wordcloud.to_file(\"black_cloud.png\")\n",
    "plt.figure(figsize = (15, 11), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.title('White Word Cloud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = string_words(series)\n",
    "\n",
    "wordcloud = WordCloud(width =800, height = 800, \n",
    "                      background_color='white', max_words = 50,\n",
    "                      collocations=False).generate(output)\n",
    "plt.figure(figsize = (10, 10), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_word_count.head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = sqf[sqf['suspect_race_description'] == 'WHITE']['spellcheck_demeanor']\n",
    "output = string_words(series)\n",
    "\n",
    "wordcloud = WordCloud(width =800, height = 800, \n",
    "                      background_color='white', max_words = 50,\n",
    "                      collocations=False).generate(output)\n",
    "plt.figure(figsize = (10, 10), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
